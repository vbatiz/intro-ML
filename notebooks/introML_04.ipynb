{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) es un algoritmo de clasificación. La idea central es que los puntos de datos con atributos similares tienden a caer en categorías similares.\n",
    "\n",
    "Veamos la imagen de abajo. Esta imagen es complicada, pero por ahora vamos a centrarnos en dónde se colocan los puntos de datos. Cada punto de datos - ya sea de color rojo, verde o blanco - tiene un valor x y un valor y. Como resultado, se puede representar gráficamente. Como resultado, se puede trazar en este gráfico bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NearestNeighbors](https://raw.githubusercontent.com/vbatiz/intro-ML/main/notebooks/images/nearest_neighbor.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, consideremos el color de los datos. El color representa la clase que el algoritmo K-Nearest Neighbor intenta clasificar. En esta imagen, los puntos de datos pueden tener la clase verde o la clase roja. Si un punto de datos es blanco, significa que aún no tiene clase. El objetivo del algoritmo es clasificar estos puntos desconocidos.\n",
    "\n",
    "Por último, considere el círculo en expansión alrededor del punto blanco. Este círculo busca los k vecinos más cercanos al punto blanco. Cuando k = 3, el círculo es bastante pequeño. Dos de los tres vecinos más cercanos son verdes y uno es rojo. En este caso, el algoritmo clasificaría el punto blanco como verde. Sin embargo, cuando aumentamos k a 5, el círculo se amplía y la clasificación cambia. Tres de los vecinos más cercanos son rojos y dos son verdes, por lo que ahora el punto blanco se clasificará como rojo.\n",
    "\n",
    "Esta es la idea central del algoritmo K-Nearest Neighbor. Si se dispone de un conjunto de datos de puntos cuya clase se conoce, se puede tomar un nuevo punto de clase desconocida, encontrar sus vecinos más cercanos y clasificarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia entre puntos - 2D\n",
    "\n",
    "En el primer ejercicio, pudimos visualizar el conjunto de datos y estimar los k vecinos más cercanos de un punto desconocido. Pero eso no lo puede hacer un ordenador.\n",
    "\n",
    "Tenemos que definir qué significa que dos puntos estén cerca o lejos. Para ello, vamos a utilizar la Fórmula de la Distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, los datos tienen dos dimensiones:\n",
    "\n",
    "- La duración de la película\n",
    "- La fecha de estreno de la película\n",
    "\n",
    "Consideremos La guerra de las galaxias y En busca del arca perdida. La guerra de las galaxias dura 125 minutos y se estrenó en 1977. En busca del arca perdida dura 115 minutos y se estrenó en 1981.\n",
    "\n",
    "La distancia entre las películas se calcula a continuación:\n",
    "\n",
    "$d = \\sqrt {\\left( {x_1 - x_2 } \\right)^2 + \\left( {y_1 - y_2 } \\right)^2 }$\n",
    "\n",
    "$d = \\sqrt {\\left( {125 - 115 } \\right)^2 + \\left( {1977 - 1981 } \\right)^2 } = 10.77$\n",
    "\n",
    "Creamos la función distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = [125, 1977]\n",
    "raiders = [115, 1981]\n",
    "mean_girls = [97, 2004]\n",
    "\n",
    "def distance(movie1, movie2):\n",
    "  length_difference = (movie1[0] - movie2[0]) ** 2\n",
    "  year_difference = (movie1[1] - movie2[1]) ** 2\n",
    "  distance = (length_difference+year_difference)**0.5\n",
    "  return distance\n",
    "\n",
    "print(distance(star_wars,raiders))\n",
    "print(distance(star_wars,mean_girls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia entre puntos - 3D\n",
    "\n",
    "Hacer una predicción de la calificación de las películas basándose únicamente en la duración y la fecha de estreno es bastante limitado. Hay muchos más datos interesantes sobre las películas que podríamos utilizar. Así que añadamos otra dimensión.\n",
    "\n",
    "Digamos que esta tercera dimensión es el presupuesto de la película. Ahora tenemos que encontrar la distancia entre estos dos puntos en tres dimensiones.\n",
    "\n",
    "![3D](https://raw.githubusercontent.com/vbatiz/intro-ML/main/notebooks/images/threed.webp)\n",
    "\n",
    "¿Y si no nos conformamos con tres dimensiones? Por desgracia, resulta bastante difícil visualizar puntos en dimensiones superiores a 3. Pero eso no significa que no podamos hallar la distancia entre ellos.\n",
    "\n",
    "La fórmula generalizada de la distancia entre los puntos A y B es la siguiente:\n",
    "\n",
    "$d = \\sqrt {\\left( {A_1 - B_1 } \\right)^2 + \\left( {A_2 - B_2 } \\right)^2 + ... + \\left( {A_n - B_n } \\right)^2 }$\n",
    "\n",
    "Aquí, $A_1-B_1$ es la diferencia entre la primera característica de cada punto. $A_n-B_n$ es la diferencia entre la última característica de cada punto.\n",
    "\n",
    "Usando esta fórmula, podemos encontrar los K vecinos más cercanos de un punto en un espacio N-dimensional. Ahora podemos utilizar tanta información sobre nuestras películas como queramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = [125, 1977, 11000000]\n",
    "raiders = [115, 1981, 18000000]\n",
    "mean_girls = [97, 2004, 17000000]\n",
    "print(distance(star_wars,raiders))\n",
    "print(distance(star_wars,mean_girls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt1, pt2):\n",
    "  distance = 0\n",
    "  for i in range(len(pt1)):\n",
    "    distance += (pt1[i] - pt2[i]) ** 2\n",
    "  return distance ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos con Diferentes Escalas: Normalización\n",
    "\n",
    "Cuando añadimos la dimensión de presupuesto, es posible que se haya dado cuenta de que hay algunos problemas con el aspecto actual de nuestros datos.\n",
    "\n",
    "Consideremos las dos dimensiones de fecha de estreno y presupuesto. La diferencia máxima entre las fechas de estreno de dos películas es de unos 125 años (los hermanos Lumière hacían películas en la década de 1890). Sin embargo, la diferencia entre el presupuesto de dos películas puede ser de millones de dólares.\n",
    "\n",
    "El problema es que la fórmula de la distancia trata todas las dimensiones por igual, independientemente de su escala. Si dos películas se estrenaran con 70 años de diferencia, eso debería ser un gran problema. Sin embargo, ahora mismo, eso equivale exactamente a dos películas que tienen una diferencia de presupuesto de 70 dólares. La diferencia en un año es exactamente igual a la diferencia en un dólar de presupuesto. Es absurdo.\n",
    "\n",
    "Otra forma de pensar en esto es que el presupuesto supera completamente la importancia de todas las demás dimensiones porque es de una escala enorme. El hecho de que dos películas se hicieran con 70 años de diferencia es esencialmente insignificante comparado con la diferencia de millones en la otra dimensión.\n",
    "\n",
    "La solución a este problema es normalizar los datos para que cada valor esté entre 0 y 1. En esta sección, vamos a utilizar la normalización mín-máx.\n",
    "\n",
    "Para ello haremos nuestra propia función para normalizar una lista de números:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(lst):\n",
    "  minimum = min(lst)\n",
    "  maximum = max(lst)\n",
    "  normalized = []\n",
    "  for valor in lst:\n",
    "    valor_normalizado = (valor-minimum)/(maximum-minimum) \n",
    "    normalized.append(valor_normalizado)\n",
    "  return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_dates = [1897, 1998, 2000, 1948, 1962, 1950, 1975, 1960, 2017, 1937, 1968, 1996, 1944, 1891, 1995, 1948, 2011, 1965, 1891, 1978]\n",
    "\n",
    "datos_normalizados = min_max_normalize(release_dates)\n",
    "print(datos_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando los vecinos más próximos (Nearest Neighbors)\n",
    "\n",
    "Ahora que nuestros datos están normalizados y sabemos cómo hallar la distancia entre dos puntos, podemos empezar a clasificar los datos desconocidos.\n",
    "\n",
    "Para ello, queremos encontrar los k vecinos más cercanos del punto no clasificado. En algunos ejercicios, aprenderemos a elegir k correctamente, pero por ahora, elijamos un número que parezca razonable. Elijamos 5.\n",
    "\n",
    "Para encontrar los 5 vecinos más cercanos, tenemos que comparar esta nueva película sin clasificar con todas las demás películas del conjunto de datos. Esto significa que vamos a utilizar la fórmula de la distancia una y otra vez. En última instancia, queremos obtener una lista ordenada de distancias y las películas asociadas a esas distancias.\n",
    "\n",
    "Podría ser algo como esto:\n",
    "\n",
    "```\n",
    "[\n",
    "  [0.30, 'Superman II'],\n",
    "  [0.31, 'Finding Nemo'],\n",
    "  ...\n",
    "  ...\n",
    "  [0.38, 'Blazing Saddles']\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "En este ejemplo, la película desconocida tiene una distancia de 0,30 a Superman II.\n",
    "\n",
    "A continuación, utilizaremos las etiquetas asociadas a estas películas para clasificar el punto sin etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usaremos un archivo que contiene dos diccionarios con información de películas\n",
    "!wget --no-check-certificate https://raw.githubusercontent.com/vbatiz/intro-ML/main/notebooks/movies.py -O movies.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.006630902005283176, 0.21843003412969283, 0.8539325842696629]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from movies import movie_dataset, movie_labels\n",
    "print(movie_dataset['Bruce Almighty'])\n",
    "print(movie_labels['Bruce Almighty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos importado un conjunto de datos de películas previamente normalizado e impreso los datos de la película Bruce Almighty. Cada película del conjunto de datos tiene tres características:\n",
    "\n",
    "- el presupuesto normalizado (dólares)\n",
    "- la duración normalizada (minutos)\n",
    "- el año de estreno normalizado.\n",
    "\n",
    "También hemos importado las etiquetas asociadas a cada película del conjunto de datos. La etiqueta asociada a Bruce Almighty es un 0, lo que indica que es una mala película. Recordemos que una película mala tiene una calificación inferior a 7,0 en IMDb.\n",
    "\n",
    "Crearemos ahora nuestra propia función de clasificación de vecinos más cercanos. La función tiene tres parámetros: el punto de datos que desea clasificar denominado unknown, el conjunto de datos que utiliza para clasificarlo denominado dataset y k, el número de vecinos que le interesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08273614694606074, 'Lady Vengeance'], [0.22989623153818367, 'Steamboy'], [0.23641372358159884, 'Fateless'], [0.26735445689589943, 'Princess Mononoke'], [0.3311022951533416, 'Godzilla 2000']]\n"
     ]
    }
   ],
   "source": [
    "def classify(unknown, dataset, k):\n",
    "  distances = []\n",
    "  for title in dataset:\n",
    "    distancia_al_punto = distance(dataset[title], unknown)\n",
    "    distances.append([distancia_al_punto,title])\n",
    "  distances.sort()\n",
    "  neighbors = distances[:k]\n",
    "  return neighbors\n",
    "\n",
    "print(classify([.4, .2, .9],movie_dataset,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando vecinos\n",
    "\n",
    "Ahora hemos encontrado los k vecinos más cercanos y los hemos almacenado en una lista que tiene este aspecto:\n",
    "\n",
    "```\n",
    "[\n",
    "  [0.083, 'Lady Vengeance'],\n",
    "  [0.236, 'Steamboy'],\n",
    "  ...\n",
    "  ...\n",
    "  [0.331, 'Godzilla 2000']\n",
    "]\n",
    "```\n",
    "\n",
    "Nuestro objetivo ahora es contar el número de películas buenas y malas en la lista de vecinos. Si hay más vecinos buenos, el algoritmo clasificará la película desconocida como buena. En caso contrario, la clasificará como mala.\n",
    "\n",
    "Para averiguar la clase de cada una de las etiquetas, tendremos que consultar nuestro conjunto de datos movie_labels. Por ejemplo, movie_labels['Akira'] nos daría 1 porque Akira está clasificada como una buena película.\n",
    "\n",
    "Te preguntarás qué pasa si hay un empate. ¿Qué pasa si k = 8 y cuatro vecinos son buenos y cuatro malos? Hay distintas estrategias, pero una forma de deshacer el empate sería elegir la clase del punto más cercano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(movie_labels['Akira'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificaremos nuestra función classify para que tome en consideración las etiquetas y determine la cantidad de vecinos buenos y malos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(unknown, dataset, labels, k):\n",
    "  distances = []\n",
    "  #Recrremos el dataset\n",
    "  for title in dataset:\n",
    "    movie = dataset[title]\n",
    "    distance_to_point = distance(movie, unknown)\n",
    "    #Agregamos la distancia y el punto asociado a ella\n",
    "    distances.append([distance_to_point, title])\n",
    "  distances.sort()\n",
    "  #Tomamos solo los k más cercanos\n",
    "  neighbors = distances[0:k]\n",
    "  num_good = 0\n",
    "  num_bad = 0\n",
    "  for neighbor in neighbors:\n",
    "    title = neighbor[1]\n",
    "    if labels[title] == 0:\n",
    "      num_bad += 1\n",
    "    elif labels[title] == 1:\n",
    "      num_good += 1\n",
    "  if num_good > num_bad:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos la nueva función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(classify([.4, .2, .9],movie_dataset, movie_labels,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
