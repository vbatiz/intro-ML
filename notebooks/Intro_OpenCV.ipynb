{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eP9VcOVoebew"
      },
      "source": [
        "# Fundamentos de OpenCV\n",
        "\n",
        "Aprenderemos como abrir archivos, verificar pixeles y algunas técnicas de procesamiento de imágenes.\n",
        "\n",
        "Usaremos las siguientes imágenes de ejemplo, que he tomado prestadas de internet, pero ustedes pueden usar la imagen que deseen.\n",
        "\n",
        "![John Wick](https://www.indiewire.com/wp-content/uploads/2019/05/07956f40-77c4-11e9-9073-657a85982e73.jpg \"John Wick\")\n",
        "\n",
        "![No idea](https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/noidea.jpg \"I have no idea\")\n",
        "\n",
        "![Que Paso Ayer](https://www.cinepremiere.com.mx/wp-content/uploads/2009/08/Critica-Que-paso-ayer.jpg \"Que paso ayer\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<p>\n",
        " Tiempo estimado: <strong>40 minutos</strong>\n",
        "</p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cIU7W8Wmebey"
      },
      "source": [
        "## Realicemos los pasos iniciales\n",
        "\n",
        "Empezaremos importando las bibliotecas que usaremos: OpenCV, Numpy, y algunas más. Algunas utilerías disponibles en los ejemplos de OpenCv para Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "TXKxw8iJebez",
        "outputId": "c2832f64-fc9b-4756-995d-d0bd6a340926"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Descargamos las imágenes de prueba y las utilerías\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/noidea.jpg \\\n",
        "    -O noidea.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://www.indiewire.com/wp-content/uploads/2019/05/07956f40-77c4-11e9-9073-657a85982e73.jpg \\\n",
        "    -O johnwick.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://www.cinepremiere.com.mx/wp-content/uploads/2009/08/Critica-Que-paso-ayer.jpg \\\n",
        "    -O quepasoayer.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://fundaciongabo.org/sites/default/files/imagenportada/2019-11/grillo-multicolor-FALSO.jpg \\\n",
        "    -O grillopillo.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/utils/common.py \\\n",
        "    -O common.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enDe5WvtWpJI"
      },
      "outputs": [],
      "source": [
        "# Importamos las bibliotecas que utilizaremos\n",
        "import cv2 #opencv automáticamente se carca como cv2\n",
        "import common #funciones útiles para openCV\n",
        "import numpy as np #Biblioteca de manipulación de matrices\n",
        "\n",
        "#Lo siguiente permite configurar comportamiento del bloc de notas\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt # permite que las imágenes se desplieguen directamente en el bloc de notas\n",
        "import pylab # Permite controlar el tamaño de las figuras\n",
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # Esto controla el tamaño de las figuras en el bloc de notas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "htK6mm-Gebe2"
      },
      "source": [
        "## Abrimos la imagen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ah762ATHebe3"
      },
      "outputs": [],
      "source": [
        "nombre = 'johnwick.jpg'\n",
        "nombre2 = 'noidea.jpg'\n",
        "nombre3 = 'quepasoayer.jpg'\n",
        "nombre4 = 'grillopillo.jpg'\n",
        "image=cv2.imread(nombre4)\n",
        "input_image=cv2.imread(nombre4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Y4-IFEEmveFU",
        "outputId": "b56407a7-9467-4f53-c661-dcfa3429c93d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "inverted = 255-gray_image\n",
        "blur = cv2.GaussianBlur(inverted, (21, 21), 0)\n",
        "invertedblur = 255-blur\n",
        "sketch = cv2.divide(gray_image, invertedblur, scale=256.0)\n",
        "cv2.imwrite(\"sketch.png\", sketch)\n",
        "plt.imshow(sketch)\n",
        "#cv2.imshow(\"Image\", sketch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ut1_Lwdgebe5"
      },
      "source": [
        "Revisamos algunas características de la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "awdTYn4Gebe6",
        "outputId": "7db15663-e154-4413-8dfc-7e4500e924ff",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "print(input_image.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "af7iQyhqebe8",
        "outputId": "d8802bcd-ad38-48de-c647-eaf2c3d5fb58"
      },
      "outputs": [],
      "source": [
        "print(input_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "UhxrodZrebe_",
        "outputId": "fbfd62ba-738a-4e99-f7c2-c8e896ba7c40"
      },
      "outputs": [],
      "source": [
        "print(input_image.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "stSDqhuBebfA"
      },
      "source": [
        "**Nota** Este último dato que nos da el tipo de dato de la imagen es una de las cosas que siempre hay que tomar en cuenta al momento de trabajar con Python, ya que podemos recibir muchos mensajes de error si no trabajamos con los tipos correctos. Lo mismo aplica para los tamaños de las matrices que utilicemos como entradas para funciones o capas de entrada en una red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "deletable": true,
        "editable": true,
        "id": "woP9RhyCebfB",
        "outputId": "f5a08e1a-e467-429f-c33d-d6e59fa7fade"
      },
      "outputs": [],
      "source": [
        "plt.imshow(input_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "6VFxWhvUebfD"
      },
      "source": [
        "Lo que podemos obervar en esta imagen en comparación a la mostrada previamente es algo clave cuando utilizamos OpenCV: no utiliza el formato RGB para almacenar las imágenes, en su lugar utiliza el formato BGR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "deletable": true,
        "editable": true,
        "id": "zgEQX0isebfD",
        "outputId": "91d351b8-3692-4280-a6bd-af86cb79bc9c"
      },
      "outputs": [],
      "source": [
        "# Separemos los canales de colores\n",
        "b,g,r=cv2.split(input_image)\n",
        "# Mostremos uno de los canales\n",
        "plt.imshow(r, cmap= 'gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "XqE1jCKaebfG"
      },
      "source": [
        "## conversiones entre espacios de colores, mezclando y separando canales\n",
        "\n",
        "Podemos convertir entre diversos espacios de colores en OpenCV fácilmente. Arriba vimos como podemos separar canales, veamos ahora un ejemplo de mezclado de canales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "deletable": true,
        "editable": true,
        "id": "Ev_3hJKLebfH",
        "outputId": "f8f2666d-cc5f-4e7b-a9eb-a2d73a1a9b33"
      },
      "outputs": [],
      "source": [
        "merged=cv2.merge([r,g,b])\n",
        "# merge takes an array of single channel matrices\n",
        "plt.imshow(merged)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "cJ-UCAynebfJ"
      },
      "source": [
        "OpenCV tiene una función específica para trabajar con espacios de colores de las imágenes, por lo que en lugar de separar los canales y volver a mezclarlos a mano, podemos usar esta función.\n",
        "\n",
        "Existen alredor de 250 banderas de colores en OpenCV para conversión y visualización. Las más comunes son COLOR_BGR2RGB para conversión a RGB, COLOR_BGR2GRAY para conversión a escala de grises y COLOR_BGR2HSV para conversión al espacio de colores: Hue, Saturation, Value. En el siguiente vínculo puedes encontrar más información sobre estas conversiones de colores: [Conversiones](https://docs.opencv.org/master/de/d25/imgproc_color_conversions.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "egPmVUvYebfK",
        "outputId": "65a3d6ad-cffc-423f-9c08-bcacf1b5f449"
      },
      "outputs": [],
      "source": [
        "# Imprime el número de mapas de colores que maneja OpenCV\n",
        "COLORflags = [flag for flag in dir(cv2) if flag.startswith('COLOR') ]\n",
        "print(len(COLORflags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwZKXL4ncJ6o",
        "outputId": "0d3c5687-8f8d-4baf-ac05-57d3fbc43ffc"
      },
      "outputs": [],
      "source": [
        "# Imprime los nombres de los mapas de colores\n",
        "print(COLORflags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_YxZITvdY2J"
      },
      "source": [
        "### Cambiemos el espacio de colores de nuestra imagen y visualicémosla de nuevo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "deletable": true,
        "editable": true,
        "id": "INRZEZdvebfM",
        "outputId": "7dc07cb0-e919-4e2c-9a2a-b7a65a92c084"
      },
      "outputs": [],
      "source": [
        "opencv_merged=cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(opencv_merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Lz_0QbNWDDEy",
        "outputId": "80ada9f7-20f8-4e11-8d18-54ccfd3b3016"
      },
      "outputs": [],
      "source": [
        "opencv_merged2=cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(opencv_merged2, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D7lU3YrezYw"
      },
      "source": [
        "## Jugando con los espacios de colores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "cUMAKambe1a0",
        "outputId": "0a563df4-b0ea-48da-ec01-e8f1e32d3fbe"
      },
      "outputs": [],
      "source": [
        "image2 = cv2.applyColorMap(input_image, cv2.COLORMAP_BONE)\n",
        "image3 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "HteJoFYnVpEd",
        "outputId": "5fef35e9-b032-4b6c-8ba1-c1b9dd1e8cc2"
      },
      "outputs": [],
      "source": [
        "image2 = cv2.applyColorMap(input_image, cv2.COLORMAP_RAINBOW)\n",
        "image3 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "02JyOwiiMqpi",
        "outputId": "730249e2-d09c-4911-cc09-20474e34b49f"
      },
      "outputs": [],
      "source": [
        "image2 = cv2.applyColorMap(input_image, cv2.COLORMAP_PINK)\n",
        "image3 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "ca0WiZEIIZIL",
        "outputId": "b9130cf4-a577-46d7-9507-d00dd81db467"
      },
      "outputs": [],
      "source": [
        "image2 = cv2.applyColorMap(input_image, cv2.COLORMAP_TWILIGHT)\n",
        "image3 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(image3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lfo1Lue9ebfN"
      },
      "source": [
        "## Obteniendo datos de la imagen y cambiando datos de la imagen.\n",
        "\n",
        "Las imágenes en OpenCV para Python son arreglos numpy. Los arreglos numpy están optimizados para realizar operaciones con arreglos de manera muy rápida y numpy nos porporciona varias funciones muy rápidas para realizar diversos cálculos sin necesidad de complicarnos mucho como programadores. Aunque usualmente se considera mala práctica acceder directamente a los pixeles, es posible hacerlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "32AQVQ0uebfO",
        "outputId": "a42fd425-b94a-4b31-c69f-524f8eb37a79"
      },
      "outputs": [],
      "source": [
        "pixel = input_image[200,500]\n",
        "print(pixel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": true,
        "editable": true,
        "id": "OE1vlYo2ebfQ",
        "outputId": "6c21cb3f-2480-468f-c2ef-6c1fe5667425"
      },
      "outputs": [],
      "source": [
        "input_image[100,100] = [0,0,0]\n",
        "pixelnew = input_image[100,100]\n",
        "print(pixelnew)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KsFd9SBzebfS"
      },
      "source": [
        "## Obteniendo y modificando regiones de una imagen.\n",
        "\n",
        "De la misma forma en que podemos acceder o modificar pixeles individuales, podemos obtener o modificar regiones de una imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "deletable": true,
        "editable": true,
        "id": "D0rwsf8sebfS",
        "outputId": "632c76a5-f427-4ffd-e719-5b0fd6aa28ce"
      },
      "outputs": [],
      "source": [
        "dogface = opencv_merged[200:400, 200:400]\n",
        "plt.imshow(dogface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYzU2PmAIcLu",
        "outputId": "ff6877d0-38ad-449d-d953-68975459d637"
      },
      "outputs": [],
      "source": [
        "dogface.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "deletable": true,
        "editable": true,
        "id": "i1xm1L5MebfU",
        "outputId": "3fa47de8-0bf9-450d-ee5c-c1f00378d79c"
      },
      "outputs": [],
      "source": [
        "imagen_original=cv2.imread(nombre)\n",
        "#fresh_image=cv2.imread(nombre) # iniciamos con una versión nueva de la imagen,\n",
        "                                  # o podríamos terminar con imágenes anidadas\n",
        "                                   # al ejecutar solo algunas partes del bloc de notas\n",
        "fresh_image=cv2.cvtColor(imagen_original, cv2.COLOR_BGR2RGB) #Corregimos color\n",
        "\n",
        "fresh_image[200:200+dogface.shape[0], 200:200+dogface.shape[1]]=dogface\n",
        "\n",
        "print(dogface.shape[0])\n",
        "print(dogface.shape[1])\n",
        "plt.imshow(fresh_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "bCVZFlDhebfW"
      },
      "source": [
        "## Rebanado de imágenes (matrices)\n",
        "En OpenCV para python, ya hemos comentado que las imágenes son arreglos de numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "deletable": true,
        "editable": true,
        "id": "9LLhUPE7ebfX",
        "outputId": "cbfbf313-7d93-4ac8-c521-ef3af4d5a704",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "freshim1 = cv2.imread(\"noidea.jpg\")\n",
        "freshim2 =cv2.cvtColor(freshim1, cv2.COLOR_BGR2RGB) #Corregimos color\n",
        "plt.imshow(freshim2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "WMsWIBJyKjZ8",
        "outputId": "6fcbfec6-3027-425f-e2d7-bd4d0b244658"
      },
      "outputs": [],
      "source": [
        "crop = freshim2[50:250, 20:350]\n",
        "plt.imshow(crop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3pURgAtbebfZ"
      },
      "source": [
        "La clave es darse cuenta que el rebanado funciona de la siguiente manera:\n",
        "```\n",
        "[top_y:bottom_y, left_x:right_x]\n",
        "```\n",
        "Esto puede verse también como:\n",
        "```\n",
        "[y:y+height, x:x+width]\n",
        "```\n",
        "\n",
        "Puedes incluso usar rebanado (slicing) para separar canales. En dicho caso lo que harías sería:\n",
        "```\n",
        "[y:y+height, x:x+width, channel]\n",
        "```\n",
        "donde channel representa el color en el que estás interesado - puede ser 0 = blue (azul), 1 = green (verde) o 2=red (rojo) if estás trabajando con la imagen por defecto de OpenCV, pero si tienes una imagen que ya has convertido pudiera ser algo diferente. El siguiente ejemplo convierte a HSV y selecciona el canal S (Saturation) de la rebanada realizada arriba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "deletable": true,
        "editable": true,
        "id": "9cSa7WDHebfZ",
        "outputId": "7fb60b13-1b0d-40b2-a2fd-b259cf9c1a61"
      },
      "outputs": [],
      "source": [
        "hsvim=cv2.cvtColor(freshim2,cv2.COLOR_BGR2HSV)\n",
        "bcrop =hsvim[100:400, 100:300, 1]\n",
        "plt.imshow(bcrop, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jEyTpSTebff"
      },
      "source": [
        "## Estadísticas y procesamiento de imágenes\n",
        "\n",
        "### Manipulaciones básicas (rotación, invertido, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "ALr_ebd8iyfh",
        "outputId": "0c20c26f-31d0-47ba-b4a5-1e31850d4589"
      },
      "outputs": [],
      "source": [
        "flipped_code_0=cv2.flip(opencv_merged,0) # vertical flip\n",
        "plt.imshow(flipped_code_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "aCUbjXxWi9IT",
        "outputId": "e9aff259-57e5-40f7-a7b0-b192742590fb"
      },
      "outputs": [],
      "source": [
        "flipped_code_1=cv2.flip(opencv_merged,1) # horizontal flip\n",
        "plt.imshow(flipped_code_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "ri-RJDlXjBYg",
        "outputId": "a14936b9-3b27-46b1-c885-e3694e5d1779"
      },
      "outputs": [],
      "source": [
        "transposed=cv2.transpose(opencv_merged)\n",
        "plt.imshow(transposed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eSoea8-szQO"
      },
      "source": [
        "## Máximo y minimo\n",
        "\n",
        "Para encontrar el máximo y mínimo de una matriz podemos usar minMaxLoc. Lo aplicaremos sobre un canal de la imagen a la vez. El siguiente código recorre cada canal (usando slicing) y obtiene los valores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l46y2aejNWv",
        "outputId": "18939eaf-06c7-4f39-aff1-a80d06acbadc"
      },
      "outputs": [],
      "source": [
        "for i in range(0,3):\n",
        "   min_value, max_value, min_location, max_location=cv2.minMaxLoc(input_image[:,:,i])\n",
        "   print(\"min {} is at {}, and max {} is at {}\".format(min_value, min_location, max_value, max_location))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNFiOf5ljqxp"
      },
      "source": [
        "## Operaciones aritméticas en imágenes\n",
        "\n",
        "OpenCV tiene muchas funciones para realizar operaciones matemáticas sobre imagen y aunque numpy tienen algunas alternativas análogas es mejor utilizar OpenCV ya que está optimizado para trabajar con imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "mSrZELEak4Bi",
        "outputId": "d9ebc14f-ecc5-4492-a483-69421efae9f8"
      },
      "outputs": [],
      "source": [
        "#Primero creamos una imegen del mismo tamaño que nuestra salida\n",
        "blank_image = np.zeros((input_image.shape), np.uint8)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "0KuQpeDzJquJ",
        "outputId": "8bf54264-3f05-47da-da26-a698e9bb2693"
      },
      "outputs": [],
      "source": [
        "blank_image[100:200,100:200,0]=140; #Démosle un cuadro verde\n",
        "\n",
        "plt.imshow(cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "XtfzJZ45J8kZ",
        "outputId": "04da8069-8e10-42a0-a0c1-ad6160dd2505"
      },
      "outputs": [],
      "source": [
        "new_image=cv2.add(blank_image,input_image) # agreguemos las dos imágenes\n",
        "\n",
        "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iio9bAqllQa_"
      },
      "source": [
        "## Reducción de ruido\n",
        "\n",
        "La reducción de ruido implica suavizar o dar efecto borroso a una imagen usando un kernel (filtro) Gaussiano. El ancho del kernel determina la cantidad de suavizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "484fDHQ5lTcl",
        "outputId": "5c4e5081-0721-4243-a39a-6e7f01fc8293"
      },
      "outputs": [],
      "source": [
        "d=3\n",
        "img_blur3 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
        "\n",
        "plt.imshow(cv2.cvtColor(img_blur3, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "LeNyFBgslvVj",
        "outputId": "38721f37-eaae-45ac-a47a-3315b36d731c"
      },
      "outputs": [],
      "source": [
        "d=5\n",
        "img_blur5 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
        "\n",
        "plt.imshow(cv2.cvtColor(img_blur5, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Oud0wCTzlvfb",
        "outputId": "3f2c5fbf-f207-4c47-fd35-b239c7377cdb"
      },
      "outputs": [],
      "source": [
        "d=15\n",
        "img_blur15 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
        "\n",
        "plt.imshow(cv2.cvtColor(img_blur15, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy7jXJZml3Fa"
      },
      "source": [
        "## Bordes\n",
        "\n",
        "### Sobel\n",
        "\n",
        "La detección de bordes trabaja en su mayoría mediante convoluciones. El detector de bordes Sobel fue una de las primeras técnicas exitosas de detección de bordes e involucra convoluciones como su núcleo central."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nni3RgjEmqXz",
        "outputId": "fd035aad-d43e-4369-81d1-488a0384b248"
      },
      "outputs": [],
      "source": [
        "sobelimage=cv2.cvtColor(input_image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sobelx = cv2.Sobel(sobelimage,cv2.CV_64F,1,0,ksize=9)\n",
        "sobely = cv2.Sobel(sobelimage,cv2.CV_64F,0,1,ksize=9)\n",
        "plt.imshow(sobelx,cmap = 'gray')\n",
        "# Sobel trabaja en x y en y, cambia sobelx a sobely en la línea de arriba y observa la diferencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVCzR7LinAZ9"
      },
      "source": [
        "### Canny\n",
        "Detección de bordes Canny es otra de las técnicas más reconocidas. Utiliza dos umbrales. El primero determina que tan probable es que Canny encuentre un borde y el segundo determina que tan probable es seguir ese borde una vez que ha sido encontrado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "ZE0RsJZjnLTN",
        "outputId": "f260fd83-542f-4913-db2c-1cea1a8d92fa"
      },
      "outputs": [],
      "source": [
        "th1=30\n",
        "th2=90 # Canny recomienda threshold 2 sea 3 veces threshold 1 - Experimenta por tu cuenta...\n",
        "d=3 # gaussian blur\n",
        "\n",
        "edgeresult=input_image.copy()\n",
        "edgeresult = cv2.GaussianBlur(edgeresult, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
        "\n",
        "gray = cv2.cvtColor(edgeresult, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "edge = cv2.Canny(gray, th1, th2)\n",
        "\n",
        "edgeresult[edge != 0] = (0, 255, 0) # toma los pixeles en edgeresult donde edge es difrente de cero y lo colorea de verde brillante\n",
        "\n",
        "plt.imshow(cv2.cvtColor(edgeresult, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIjES0LJWYjA"
      },
      "source": [
        "# Clasificación utilizando Cascade\n",
        "\n",
        "Una de las tareas principales de la Visión Computacional es la deteción de objetos.\n",
        "\n",
        "La detección de objetos utilizando \"Haar feature-based cascade classifiers\" es un método efectivo de detección propuesto por Paul Viola y Michael Jones en su [artículo](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf) y mejorado posteriormente por [Rainer Leinhart](http://wiki.opencv.org.cn/images/5/52/MRL-TR-May02-revised-Dec02.pdf).\n",
        "\n",
        "OpenCV proporciona modelos preentrenados, que pueden leerse utilizando el método: `cv2.CascadeClassifierload`. Estos modelos preentrenados se encuentran en la carpeta data de la instalación de OpenCV o pueden descargarse de [aquí](https://github.com/opencv/opencv/tree/3.4/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGuIKQ5PYINH",
        "outputId": "5e35c1fa-5218-448c-cbbc-5f60554c03d1"
      },
      "outputs": [],
      "source": [
        "# Descargamos la imagen de prueba, los modelos preentrenados y utilerías.\n",
        "!wget --no-check-certificate \\\n",
        "    https://media.wwdjapan.com/wp-content/uploads/2018/07/14124728/180702-03-1041.jpg \\\n",
        "    -O personas.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://www.noraemagazine.com/wp-content/uploads/2020/09/MAMAMOO2-1.png \\\n",
        "    -O personas2.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://upload.wikimedia.org/wikipedia/commons/e/e4/Blackpink_in_2020_for_PUBG_Mobile.png \\\n",
        "    -O personas3.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/test.jpg \\\n",
        "    -O personas4.jpg\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/haarcascade_frontalface_default.xml \\\n",
        "    -O haarcascade_frontalface_default.xml\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/haarcascade_smile.xml \\\n",
        "    -O haarcascade_smile.xml\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/assets/haarcascade_eye.xml \\\n",
        "    -O haarcascade_eye.xml\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/computationalcore/introduction-to-opencv/master/utils/common.py \\\n",
        "    -O common.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMjphmrAYWJt"
      },
      "outputs": [],
      "source": [
        "# Cargamos las bibliotecas necesarias\n",
        "import cv2 #opencv itself\n",
        "import common #some useful opencv functions\n",
        "import numpy as np # matrix manipulations\n",
        "\n",
        "#the following are to do with this interactive notebook code\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
        "import pylab # this allows you to control figure size\n",
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2APJcC_hYfWA",
        "outputId": "50ac3da6-eecb-4350-8bde-ae0a1f806a72"
      },
      "outputs": [],
      "source": [
        "# Load the test image and create a greyscale copy of it to be used in the classifiers\n",
        "\n",
        "base_image = cv2.imread('personas4.jpg')\n",
        "grey = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(cv2.cvtColor(base_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxJEjxpFYpG6"
      },
      "source": [
        "## Detección de rostros\n",
        "\n",
        "Usaremos el modelo preentrenado haarcascade_frontalface_default.xml para detectar rostros en la foto.\n",
        "\n",
        "Notarán que en los ejemplos se vuelve a cargar la imagen a color en cada ocasión, esto es debido a que la función imshow sobrescribe la imagen original con los recuadros pero usaremos siempre la misma imagen en escala de grises para la detección."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "80S29LgFZJpC",
        "outputId": "9d9346d4-8727-4c36-d1d2-e3cc156b7d06"
      },
      "outputs": [],
      "source": [
        "# Modelo preentrenado face cascade\n",
        "test_image = cv2.imread('personas4.jpg')\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "faces = face_cascade.detectMultiScale(grey, 1.3, 5)\n",
        "for (x,y,w,h) in faces:\n",
        "     cv2.rectangle(test_image,(x,y),(x+w,y+h),(0, 255, 0),2) #(152, 167, 232)\n",
        "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpx1YnYjZbFJ"
      },
      "source": [
        "## Detección de sonrisas\n",
        "\n",
        "Usaremos el modelo preentrenado haarcascade_smile.xml para detectar sonrisas en la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "8nXan_RTZj5W",
        "outputId": "8da0f857-5b67-45a0-dd2f-cd0996d1c201"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.imread('personas4.jpg')\n",
        "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
        "smiles = smile_cascade.detectMultiScale(grey, 1.1, 20)\n",
        "for (x,y,w,h) in smiles:\n",
        "     cv2.rectangle(test_image,(x,y),(x+w,y+h),(84,107,0),2)\n",
        "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laC05FnRZrTg"
      },
      "source": [
        "Como podemos observar, si detecta las sonrisas de las personas correctamente, pero con algunas imágenes puede haber falsos positivos, esto es normal en los modelos preentrenados cascade, para mejorar los resultados, buscaremos sonrisas en los rostros previamente detectados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "E4WKWixZZ_St",
        "outputId": "ea777fa8-7c97-456d-cc33-9d0f809fead8"
      },
      "outputs": [],
      "source": [
        "# this is a pre-trained face cascade\n",
        "test_image = cv2.imread('personas4.jpg')\n",
        "for (x,y,w,h) in faces:\n",
        "  for (x_s,y_s,w_s,h_s) in smiles:\n",
        "    if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):\n",
        "      cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(0,255,0),2)\n",
        "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29GrhVebcDbg"
      },
      "source": [
        "## Detección de ojos\n",
        "\n",
        "Utilizaremos el modelo preentrenado haarcascade_eye.xml para detectar ojos en la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "i-Llu56mcP9B",
        "outputId": "5c742e2a-ca3c-455c-94fc-b7377ed6d887"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.imread('personas4.jpg')\n",
        "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
        "eyes = eye_cascade.detectMultiScale(grey, 1.2, 1)\n",
        "for (x,y,w,h) in eyes:\n",
        "     cv2.rectangle(test_image,(x,y),(x+w,y+h),(255,255,255),2)\n",
        "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGbGDXfDcWFD"
      },
      "source": [
        "De igual forma que con las sonrisas pudiera ocurrir que ciertas imágenes arrojen falsos positivos por lo que podemos usar la misma técnica de solo buscar en los rostros detectados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "YhPUQ53Acf_0",
        "outputId": "8b4291ed-8612-4c2f-9cdb-9523851f6ba1"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.imread('personas4.jpg')\n",
        "for (x,y,w,h) in faces:\n",
        "  #cv2.rectangle(smile_faces_base_image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  for (x_s,y_s,w_s,h_s) in eyes:\n",
        "    if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):\n",
        "      cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(255,255,255),2)\n",
        "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB43CbP1cnJ9"
      },
      "source": [
        "## Hagamos ahora la detección de todo junto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "O2KmE6mecq0O",
        "outputId": "91e9be63-cdd6-49a0-b849-5a0c6c5f4d7c"
      },
      "outputs": [],
      "source": [
        "test_image = cv2.imread('personas4.jpg')\n",
        "for (x,y,w,h) in faces:\n",
        "  cv2.rectangle(test_image,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  for (x_s,y_s,w_s,h_s) in eyes:\n",
        "    if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):\n",
        "      cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(255,255,255),2)\n",
        "  for (x_s,y_s,w_s,h_s) in smiles:\n",
        "    if( (x <= x_s) and (y <= y_s) and ( x+w >= x_s+w_s) and ( y+h >= y_s+h_s)):\n",
        "      cv2.rectangle(test_image, (x_s,y_s),(x_s+w_s,y_s+h_s),(0,255,0),2)\n",
        "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUua6s3Lc3JV"
      },
      "source": [
        "Si bien es cierto que en la actualidad la mayor parte de la detección de objetos se realiza con modelos de redes neuronales profundas, el método de Viola Jones para la detección de rostros es todavia un detector bastante respetado y sin duda OpenCV sigue siendo muy utilizado aún en la actualidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6LUTUo2PyL5"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "1. Fundamentos de OpenCV recuperado de:\n",
        "https://colab.research.google.com/github/computationalcore/introduction-to-opencv/blob/master/notebooks/1-Fundamentals.ipynb\n",
        "\n",
        "2. Página oficial de OpenCV, https://opencv.org/.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
