{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US9n0azPnfAV"
      },
      "source": [
        "# Regresión Simple con tensorflow, Pandas y el dataset Auto MPG\n",
        "\n",
        "Se utilizará el dataset clásico conocido como [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) y se construirá un modelo para predecir la eficiencia de vehículos de los años de 1970 a 1980 (rango de años de los que contiene datos el dataset en cuestión). Entre los atributos que usaremos estarán los cilindros, desplazamiento, potencia y peso del automóvil."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwvpkT1VoBaY",
        "outputId": "45aaf05b-abaa-425e-b600-1166fcf47af2"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFLedPb2oEGV"
      },
      "source": [
        "# El Dataset Auto MPG\n",
        "\n",
        "Este dataset está disponible en el repositorio de [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php).\n",
        "\n",
        "## Obtenemos los datos usando Keras para traerlo del repositorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUS2-hbsoiT6",
        "outputId": "8eb87299-72fe-43b7-d39c-5c9010272d15"
      },
      "outputs": [],
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "print(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ix9uEI-oq8F"
      },
      "source": [
        "## Usamos pandas para importarlo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vjG1PG-uouWH",
        "outputId": "aeee03ba-ba2c-47d3-bf70-99febe5b3cd4"
      },
      "outputs": [],
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LhQvszy1l_c",
        "outputId": "406c0fe6-6e88-4667-9d14-9cf234600f5b"
      },
      "outputs": [],
      "source": [
        "print(dataset[\"Horsepower\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osCI_ax-oyHd"
      },
      "source": [
        "## Pre-procesamos los datos\n",
        "\n",
        "Revisamos si hay valores desconocidos en los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99YDn2BDpBV5",
        "outputId": "984bd01b-4c2f-4953-ce68-4a44647ed2c4"
      },
      "outputs": [],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma8pg_WdpBCw"
      },
      "source": [
        "Eliminados las filas que contienen valores desconocidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6I4fvtqo9CT"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9sohqikpVtM"
      },
      "source": [
        "La columna \"Origin\" no es numérica, la convertiremos a valores de 0 o 1, usando lo que se conoce en este ámbito como \"one-hot\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KW0v2oGpjMn"
      },
      "outputs": [],
      "source": [
        "origin = dataset.pop('Origin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OBy9P-3CplYT",
        "outputId": "d7205bce-ead3-44ac-8c01-ab569fb6d6c2"
      },
      "outputs": [],
      "source": [
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9JJzjwApr8r"
      },
      "source": [
        "## Separemos los datos en entrenamiento y prueba.\n",
        "\n",
        "El conjunto de datos de prueba lo usaremos para evaluar nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpd1qZKoqNcV"
      },
      "outputs": [],
      "source": [
        "# dataset de entrenamiento\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "xdIpe8Oz3YqN",
        "outputId": "f3847d6f-7462-4f03-93fb-c4bf3331f0ff"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQVAgojHqXuC",
        "outputId": "af0670d0-edb1-4e22-e3cf-454acc81feec"
      },
      "outputs": [],
      "source": [
        "train_dataset.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13gljL0Kp1sn"
      },
      "outputs": [],
      "source": [
        "# dataset de prueba, del original eliminamos todos los elementos del dataset de entrenamiento\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiZrQQv0qmNZ"
      },
      "source": [
        "## Revisamos los datos\n",
        "\n",
        "Revisamos la distribución conjunta de un par de columna del conjunto de datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "vjpXiIhLqwtA",
        "outputId": "ec3e4bce-f3ac-46cf-c88e-91202fb61134"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDSol7jaq0EX"
      },
      "source": [
        "### Revisamos las estadísticas generales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "UVhB1183q4Vw",
        "outputId": "e4b26212-2f9e-421f-8e1c-adeba3ee8f7b"
      },
      "outputs": [],
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Cf1e-2rBpy"
      },
      "source": [
        "## Separamos las características de las etiquetas\n",
        "\n",
        "Los valores de las etiquetas será lo que el modelo buscará predecir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5fFKubpq7Da"
      },
      "outputs": [],
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F47OJ2PP5WTh",
        "outputId": "9c9e54c6-f547-4ee8-9fcc-664a27008f35"
      },
      "outputs": [],
      "source": [
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvb3WFLsrOtl"
      },
      "source": [
        "## Normalizamos los datos\n",
        "\n",
        "Si observamos los datos de las diferentes características en las estadísticas más arriba podemos observar que se manejan rangos muy diferentes en cada una de ellas.\n",
        "\n",
        "Es común y además buena práctica normalizar los datos para facilitar el entrenamiento.\n",
        "\n",
        "**Nota:** Aunque generamos intencionalmente estas estadísticas solo del conjunto de datos de entrenamiento, estas estadísticas también se utilizarán para normalizar el conjunto de datos de prueba. Necesitamos hacer eso para proyectar el conjunto de datos de prueba en la misma distribución en la que el modelo ha sido entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfoUW3fgq_yJ"
      },
      "outputs": [],
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmTjfxcK51o1"
      },
      "outputs": [],
      "source": [
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmP3kObUsQ2B"
      },
      "source": [
        "## Definimos el modelo\n",
        "\n",
        "Aquí, utilizaremos un modelo secuencial con dos capas ocultas densamente conectadas y una capa de salida que devuelve un único valor continuo. Los pasos de construcción del modelo se envuelven en una función, build_model, ya que crearemos un segundo modelo, más adelante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdI2eu9FsQS4"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zQZ_sfNsZzS"
      },
      "outputs": [],
      "source": [
        "model = build_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkc1oi-rscEt"
      },
      "source": [
        "## Revisamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f5gR3LLsejo",
        "outputId": "64b29efb-fb95-42b0-e828-0bfb81660382"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx_AqZacshlG"
      },
      "source": [
        "## Probando el modelo\n",
        "\n",
        "Tomaremos un lote de 10 ejemplos de los datos de entrenamiento y llamaremos a `model.predict` con dicho lote."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bMvVnz9sxaS",
        "outputId": "8182cbea-4a23-406a-a07d-e994979d8edd"
      },
      "outputs": [],
      "source": [
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXtFVa6as8Bn"
      },
      "source": [
        "## Entrenamos al modelo\n",
        "\n",
        "Entrenaremos al modelo por 1000 épocas, guardaremos los resultados de precisón del entrenamiento y validación en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgzAHI9gtRa3",
        "outputId": "451eb8c1-bcc9-4c02-9f50-9a9b52cd96cf"
      },
      "outputs": [],
      "source": [
        "# Desplegamos el progreso del entrenamiento imprimiento un punto por cada época completada\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ldBCXZLtcTz"
      },
      "source": [
        "## Visualicemos el progreso del entrenamiento del modelo usando las estadísticas almacenadas en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nF-OjfWptm2U",
        "outputId": "83f5948a-043d-4505-e9cd-2af576e127dd"
      },
      "outputs": [],
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "JjvZ8KCEtr6a",
        "outputId": "7598daa2-fdb9-451c-c02d-0706f96d7115"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mae'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mae'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-QJ5L2utwgW"
      },
      "source": [
        "Este gráfico muestra poca mejora, o incluso degradación en el error de validación después de aproximadamente 100 épocas. Actualicemos la llamada `model.fit` para detener automáticamente el entrenamiento cuando el puntaje de validación no mejore. Utilizaremos una **devolución de llamada de EarlyStopping** que pruebe una condición de entrenamiento para cada época. Si transcurre una cantidad determinada de épocas sin mostrar mejoría, entonces detiene automáticamente el entrenamiento.\n",
        "\n",
        "Puedes obtener más información sobre esta devolución de llamada [aquí](https://www.tensorflow.org/versions/master/api_docs/python/tf/keras/callbacks/EarlyStopping)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "_PDxyMH3t5C1",
        "outputId": "4a53c1c1-915d-4828-a968-550489ebcc05"
      },
      "outputs": [],
      "source": [
        "model = build_model()\n",
        "\n",
        "# El parámetro \"patience\" es la cantidad de épocas que se revisará por una mejora, si la mejora no ocurre se detiene el proceso.\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeHfyyC-uAB-"
      },
      "source": [
        "El gráfico muestra que en el conjunto de validación, el error promedio generalmente es de alrededor de +/- 2 MPG. ¿Es esto bueno? Esto siempre dependerá de ustedes y de lo que consideren aceptable.\n",
        "\n",
        "Veamos qué tan bien generaliza el modelo al usar el conjunto ** test **, que no usamos al entrenar el modelo. Esto nos dice qué tan bien podemos esperar que el modelo prediga cuándo lo usamos en el mundo real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3z3dW0duMbj",
        "outputId": "d5b8e02b-0398-4ef6-b502-ed19e5da1242"
      },
      "outputs": [],
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8ANFLDHuPb4"
      },
      "source": [
        "## Hagamos predicciones\n",
        "\n",
        "Usaremos los datos del conjunto de pruebas para predecir los valores de MPG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "lA5r4VAzuYGd",
        "outputId": "63729f47-2161-4e83-b399-9a35d4090131"
      },
      "outputs": [],
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06NZ-NCJua_E"
      },
      "source": [
        "Parece que nuestro modelo predice razonablemente bien. Echemos un vistazo a la distribución de errores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "c40ZpHtmueNV",
        "outputId": "b09573aa-fb8d-4c75-d1d8-993e12be1796"
      },
      "outputs": [],
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ILHnsfAug93"
      },
      "source": [
        "No es del todo gaussiano (curva de campana de la distribución normal), pero podríamos esperar eso porque el número de muestras es muy pequeño."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_51kksr3unnE"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "Este bloc de notas introdujo algunas técnicas para manejar un problema de regresión.\n",
        "\n",
        "* El error cuadrático medio (MSE) es una función de pérdida común utilizada para problemas de regresión (se utilizan diferentes funciones de pérdida para problemas de clasificación).\n",
        "* Del mismo modo, las métricas de evaluación utilizadas para la regresión difieren de la clasificación. Una métrica de regresión común es el error absoluto medio (MAE).\n",
        "* Cuando las características de datos de entrada numéricos tienen valores con diferentes rangos, cada característica debe escalarse independientemente al mismo rango.\n",
        "* Si no hay muchos datos de entrenamiento, una técnica es preferir una red pequeña con pocas capas ocultas para evitar el sobreajuste.\n",
        "* La detención temprana es una técnica útil para evitar el sobreajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip0vM51Cuwel"
      },
      "source": [
        "Basado en la documentación de Tensorflow, disponible en: https://www.tensorflow.org/tutorials/keras/regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muzY4hOuu_gp"
      },
      "outputs": [],
      "source": [
        "#@title MIT License\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
