{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KS5OAou53M3"
      },
      "source": [
        "## Las redes convolucionales\n",
        "\n",
        "![title](https://miro.medium.com/max/700/1*XEPeVUd1ePhcE1-MU_eWsg.png)\n",
        "\n",
        "Las redes neuronales convolucionales es un algoritmo de aprendizaje profundo (Deep Learning) que está diseñado para trabajar con imágenes, tomando estas como entrada (input) , asignándole importancias (pesos) a ciertos elementos en la imagen para así poder diferenciar unos de otros. Este es uno de los principales algoritmos que ha contribuido en el desarrollo y perfeccionamiento del campo de Visión por computadora.\n",
        "Las redes convolucionales contienen varias capas ocultas (hidden layers), donde las primeras puedan detectar líneas, curvas y así se van especializando hasta poder reconocer formas complejas como un rostro, siluetas, etc. Las tareas comunes de este tipo de redes son:\n",
        "\n",
        "* Detección o categorización de objetos\n",
        "* Clasificación de escenas\n",
        "* Clasificación de imágenes en general.\n",
        "\n",
        "Las redes toman como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a 784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n",
        "\n",
        "![title](https://miro.medium.com/max/700/1*_Cb1dzBhciwRi9y1-J6qjQ.png)\n",
        "\n",
        "Pero antes es necesario normalizar los datos, es decir que nuestros pixeles que originalmente tienen valores entre 0 y 255, convertirlos a valores entre 0 y 1, esto podemos lograrlo dividiendo cada uno de los pixeles al valor más alto que estos tienen es decir 255.\n",
        "\n",
        "#Kernel\n",
        "\n",
        "El kernel en las redes convolucionales se considera como el filtro que se aplica a una imagen para extraer ciertas características importantes o patrones de esta.\n",
        "Por ejemplo si tenemos una imagen como la siguiente.\n",
        "\n",
        "![title](https://miro.medium.com/max/295/1*awhD4TI4-HaJP-BrfssL1Q.png)\n",
        "\n",
        "Aplicandole un kernel de bordes, se veria como la siguiente imagen.\n",
        "\n",
        "![title](https://miro.medium.com/max/309/1*fiU2w-EqbKJhHoV9MDCtUg.png)\n",
        "\n",
        "Entre las características importantes para lo que sirve el kernel son detectar bordes, enfoque, desenfoque, entre otros. Esto se logra al realizar la convolución entre la imagen y el kernel.\n",
        "\n",
        "#La convolucion\n",
        "\n",
        "Uno de los procesos más distintivos de estas redes son las convoluciones. El cual consiste en tomar un grupo de píxeles de la imagen de entrada e ir realizando un producto escalar con un kernel. El kernel recorrerá todas las neuronas de entrada y obtendremos una nueva matriz, la cual será una de las hidden layers. En el caso de que la imagen sea de color se tendrán 3 kernels del mismo tamaño que se sumarán para obtener una imagen de salida.\n",
        "\n",
        "![title](https://miro.medium.com/max/700/1*67NJ1OXILVMUx-tCqaWUZg.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uECf4GS7S1Yo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n3Ok47QofdW"
      },
      "source": [
        "## Descargando y explorando el dataset\n",
        "\n",
        "Este dataset contiene cerca de 37,000 fotos de flores. El dataset contiene 5 sub directorios, 1 por cada clase:\n",
        "\n",
        "```\n",
        "flower_photo/\n",
        "  daisy/\n",
        "  dandelion/\n",
        "  roses/\n",
        "  sunflowers/\n",
        "  tulips/\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l1w2fgkTP6P",
        "outputId": "1bbfa0f5-e9e8-4dcf-c993-1997842dc03e"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3T_gAN3o5fe"
      },
      "source": [
        "Después de la descarga, tendrás una copia del datset a tu disposición. Hay 3,670 imágenes en total:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mKacC_JTQLa",
        "outputId": "0e4dd414-7d51-45e9-a05d-be7b7b12bb5b"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OtGllYGpLH3"
      },
      "source": [
        "Mostremos algunas rosas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "um7GNbTpTQQT",
        "outputId": "d2c41e98-dfe4-42e3-aa71-f858e26498b5"
      },
      "outputs": [],
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[15]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-1z1dbTpNoP"
      },
      "source": [
        "Y ahora algunos tulipanes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "ywPQSzVmTlhz",
        "outputId": "27ea49c2-bbd5-4fc1-9a59-b3807b10d886"
      },
      "outputs": [],
      "source": [
        "tulips = list(data_dir.glob('tulips/*'))\n",
        "PIL.Image.open(str(tulips[7]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps4R24tYpeJS"
      },
      "source": [
        "## Cargando el dataset con keras.preprocessing\n",
        "\n",
        "Carguemos las imágenes usando la utilidad `image_dataset_from_directory`. Esto lo llevará de un directorio de imágenes en el disco a un **`tf.data.Dataset`** en solo un par de líneas de código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0nkWEqnqAkg"
      },
      "source": [
        "### Creando el conjunto de datos\n",
        "\n",
        "Definimos algunos parámetros para el cargador del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF4hUK3bTnaW"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sprTdqj8qNrf"
      },
      "source": [
        "Es una buena práctica utilizar una división de validación al desarrollar su modelo. Usemos el 80% de las imágenes para entrenamiento y el 20% para validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjgP9gLiqLVy",
        "outputId": "b4666728-fb19-4060-d9d4-0fb2ab3a53e0"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb1dKBgCTnui",
        "outputId": "07e95f44-f7e6-4bc5-d030-5185a99c5587"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Jj1vmqqVsI"
      },
      "source": [
        "Los nombres de las clases los encontraremos en el atributo `class_names` de ambos conjuntos de datos. Corresponden a los nombres de los directorios en orden alfabético."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi_QJ005Twmc",
        "outputId": "cb26c51a-b94a-4cef-d864-3b3f05960a49"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb1v3RD-qqQc"
      },
      "source": [
        "## Visualizando los datos\n",
        "\n",
        "Mostremos las primeras 9 imágenes del dataset de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "rn7EryqNTwr_",
        "outputId": "10ceedef-2c7e-414d-b41c-cb9dcc080a3a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z85ERlvq03K"
      },
      "source": [
        "Entrenaremos nuestro modelo usando estos datasets pasándoselos a la función model.fit más adelante. Antes vamos a recuperar un lote de imágenes de manera manual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWTjF6DxTwvJ",
        "outputId": "c1e067bd-0f0b-4b3b-bc1f-92743d3efb1d"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV3DPU75snqc"
      },
      "source": [
        "`image_batch` es un tensor de la forma (32, 180, 180, 3). Se trata de un lote de 32 imágenes de forma 180x180x3 (la última dimensión se refiere a los canales de color RGB). `label_batch` es un tensor de la forma (32,), estas son etiquetas correspondientes a las 32 imágenes.\n",
        "\n",
        "Puede llamar a `.numpy()` en los tensores `image_batch` y `labels_batch` para convertirlos en un `numpy.ndarray` ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRFkTQY4s65a"
      },
      "source": [
        "## Configurar el conjunto de datos para un mejor rendimiento.\n",
        "\n",
        "`Dataset.cache()` mantiene las imágenes en la memoria después de que se cargan fuera del disco durante la primera época. Esto asegurará que el conjunto de datos no se convierta en un cuello de botella mientras entrena su modelo. Si su conjunto de datos es demasiado grande para caber en la memoria, también puede usar este método para crear una caché en disco de alto rendimiento.\n",
        "\n",
        "`Dataset.prefetch()` superpone el preprocesamiento de datos y la ejecución del modelo durante el entrenamiento.\n",
        "\n",
        "Puede obtener más información al respecto [aquí](https://www.tensorflow.org/guide/data_performance#prefetching)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBNhC6XPT9g7"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "val_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2LikjQitkjw"
      },
      "source": [
        "## Estandarizar los datos\n",
        "\n",
        "Los valores del canal RGB están en el rango [0, 255] . Esto no es ideal para una red neuronal; en general, debe intentar que los valores de entrada sean pequeños. Aquí, estandarizará los valores para que estén en el rango [0, 1] mediante el uso de una capa de cambio de escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1su6XJET9nO"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3qx1DK3T9sQ",
        "outputId": "83fe22a8-efaa-4fd6-f115-557c3278473c"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Note que los valores de los pixeles están ahora entre `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUI15tz8t3O7"
      },
      "source": [
        "## Crear el modelo\n",
        "\n",
        "El modelo consta de tres bloques de convolución con una capa de grupo máxima (maxpooling) en cada uno de ellos. Hay una capa completamente conectada (fully connected) con 128 unidades en ella que se activa mediante una función de activación relu y al final una capa densa con el número de unidades igual al número de clases. Este modelo no ha sido ajustado para una alta precisión, el objetivo de este tutorial es mostrar un enfoque estándar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcGGkLT4T9uW"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY-HJxFGukyP"
      },
      "source": [
        "## Compilando el modelo\n",
        "\n",
        "Para este ejemplo usaremos como opimizador: `optimizers.Adam` y la función de pérdida `losses.SparseCategoricalCrossentropy` . Para ver la precisión del entrenamiento y la validación para cada época de entrenamiento, pasaremos el argumento de metrics ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efs8Uu2zT9wF"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aNd0VPXvDw8"
      },
      "source": [
        "## Resumen del modelo\n",
        "\n",
        "Revisemos las capas del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVvnn8bbUTAV",
        "outputId": "ec1b55de-37ea-48d2-c212-60a260e0f926"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqk5FD1tvO-X"
      },
      "source": [
        "## Revisamos si contamos con GPU\n",
        "\n",
        "En Colab podemos activarlo en el menú: [Entorno de ejecución] [Cambio tipo de entorno de ejecución]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnPC7cqU-FVt",
        "outputId": "417b692f-d854-4100-8e3a-710d1acad525"
      },
      "outputs": [],
      "source": [
        "#Check on edit - notebook settings - gpu acceleration\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFGOA0unvkHR"
      },
      "source": [
        "## Entrenando al modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiC4ODiPUTDE",
        "outputId": "58addbaa-5260-4ff5-cf88-b5e32531a5f0"
      },
      "outputs": [],
      "source": [
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    epochs=10\n",
        "    history = model.fit(\n",
        "      train_ds,\n",
        "      validation_data=val_ds,\n",
        "      epochs=epochs\n",
        "    )\n",
        "    return history\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    epochs=10\n",
        "    history = model.fit(\n",
        "      train_ds,\n",
        "      validation_data=val_ds,\n",
        "      epochs=epochs\n",
        "    )\n",
        "    return history\n",
        "\n",
        "# Elija la función dependiendo de si usará GPU o no\n",
        "history = gpu() #cpu()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrsFV29q_Wkp"
      },
      "outputs": [],
      "source": [
        "# cpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQLocmdnv3uq"
      },
      "source": [
        "## Revisemos los resultados del entrenamiento\n",
        "\n",
        "Crearemos gráficos de pérdida y precisión en los conjuntos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "LJKM61JlUTLM",
        "outputId": "f57ecffa-5c41-4a70-fdc5-18340adb2a16"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs = 10\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7yYLUaNwCLu"
      },
      "source": [
        "En caso de que los valores de exactitud (accuracy) y pérdida (loss) se encuentren con un margen alto de diferencia podríamos haber caído en sobreajuste. Veamos como pudiéramos combatirlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMrpw3sGwGHQ"
      },
      "source": [
        "## Sobreajuste (overfitting)\n",
        "\n",
        "En los gráficos anteriores, la precisión del entrenamiento aumenta linealmente con el tiempo, mientras que la precisión de la validación se detiene alrededor del 60% en el proceso de entrenamiento. Además, la diferencia de precisión entre la precisión del entrenamiento y la validación es notable, una señal de sobreajuste .\n",
        "\n",
        "Cuando hay una pequeña cantidad de ejemplos de entrenamiento, el modelo a veces aprende de ruidos o detalles no deseados de ejemplos de entrenamiento, hasta el punto de que impacta negativamente el rendimiento del modelo en nuevos ejemplos. Este fenómeno se conoce como sobreajuste. Significa que el modelo tendrá dificultades para generalizar en un nuevo conjunto de datos.\n",
        "\n",
        "Hay varias formas de luchar contra el sobreajuste en el proceso de formación. En este tutorial, usará el aumento de datos y agregará Dropout a su modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5aT2TPgwRXy"
      },
      "source": [
        "## Aumento de datos\n",
        "\n",
        "El sobreajuste generalmente ocurre cuando hay una pequeña cantidad de ejemplos de entrenamiento. El aumento de datos adopta el enfoque de generar datos de entrenamiento adicionales a partir de sus ejemplos existentes al aumentarlos mediante transformaciones aleatorias que producen imágenes de aspecto creíble. Esto ayuda a exponer el modelo a más aspectos de los datos y a generalizar mejor.\n",
        "\n",
        "Implementará el aumento de datos utilizando capas experimentales de preprocesamiento de Keras . Estos pueden incluirse dentro de su modelo como otras capas y ejecutarse en la GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBNq-jrwbuH-"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
        "                                                 input_shape=(img_height,\n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76wXEScAwaad"
      },
      "source": [
        "Revisemos cómo se ven algunos ejemplos aumentados aplicando el aumento de datos a la misma imagen varias veces:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "HCbIK3sGbuTD",
        "outputId": "0239828f-3126-46bb-c3ac-0d2a69a2cd98"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyj2EPQZwi24"
      },
      "source": [
        "## Pérdida/abandono (dropout)\n",
        "\n",
        "Otra técnica para reducir el sobreajuste es introducir Dropout en la red, una forma de regularización .\n",
        "\n",
        "Cuando aplica Dropout a una capa, elimina aleatoriamente (estableciendo la activación en cero) una cantidad de unidades de salida de la capa durante el proceso de entrenamiento. La deserción toma un número fraccionario como valor de entrada, en la forma como 0,1, 0,2, 0,4, etc. Esto significa eliminar el 10%, 20% o 40% de las unidades de salida al azar de la capa aplicada.\n",
        "\n",
        "`layers.Dropout`una nueva red neuronal usando `layers.Dropout`, `layers.Dropout` y luego `layers.Dropout` usando imágenes aumentadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mZzCQ-EbuYX"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtIRTFfMw1vu"
      },
      "source": [
        "## Compilar y entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VVLa28Ib6jZ",
        "outputId": "e6425359-01ba-43e6-d563-bdad637451ed"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "epochs = 15\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46VryUfBw9yw"
      },
      "source": [
        "## Revisemos ahora los nuevos resultados del entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "A6bZPvmNb6vs",
        "outputId": "dbc9374d-d91c-422e-d877-f486b0d989d6"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTF7JBR7xLR-"
      },
      "source": [
        "## Predecir usando nuevos datos\n",
        "\n",
        "Finalmente, usemos nuestro modelo para clasificar una imagen que no se incluyó en los conjuntos de entrenamiento o validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S57-EsMAb60h",
        "outputId": "08f29698-b5ee-4f71-a45e-9587a31683c1"
      },
      "outputs": [],
      "source": [
        "sunflower_url = \"https://www.latercera.com/resizer/v0X72DUmELmZrsZfVhAzoHtT9yU=/380x570/smart/arc-anglerfish-arc2-prod-copesa.s3.amazonaws.com/public/AI4BMPQE4BEFVAE7M4ARBF3SI4.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('AI4BMPQE4BEFVAE7M4ARBF3SI4', origin=sunflower_url)\n",
        "\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    sunflower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8s57ElbgYHS",
        "outputId": "f3ea7835-7d6d-4788-f5e8-b8d192905aad"
      },
      "outputs": [],
      "source": [
        "print(score)\n",
        "print(class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
