{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvgO9d3wdsk3"
      },
      "source": [
        "# **Clasificador de ropa de moda con TensorFlow**\n",
        "\n",
        "En este bloc de notas se construirá un clasificador de ropa e introduciremos el uso de la biblioteca **Tensorflow** y uno de sus módulos más conocidos: **Keras**. Se utilizará uno de los datasets clásicos conocido como [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKRP4yrjdjHE",
        "outputId": "ccee4bd2-99aa-43e8-ceb1-14ee39b3a036"
      },
      "outputs": [],
      "source": [
        "# TensorFlow y tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Bibliotecas de ayuda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHGYtb7ueYBR"
      },
      "source": [
        "Importamos el dataset de Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHgpuxUseFJc",
        "outputId": "56a8c3d4-bdc1-4860-d1af-6fa3ca88d507"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1n69aSKe4Se"
      },
      "source": [
        "Este Dataset contiene imágenes en arreglos de Numpy de 28x28, donde cada elemento representa un color usando la escala RGB (0 a 255). Las etiquetas (labels) son un arreglo de enteros, que van de 0 a 9. Estos corresponden a la clase (class) de ropa que la imagen representa.\n",
        "\n",
        "```\n",
        "0\tT-shirt/top (Playera/Top)\n",
        "1\tTrouser (Pantalón)\n",
        "2\tPullover (Suéter ligero cerrado y con escote en pico)\n",
        "3\tDress (Vestido)\n",
        "4\tCoat (Abrigo)\n",
        "5\tSandal (Sandalia)\n",
        "6\tShirt (Camisa)\n",
        "7\tSneaker (Tenis)\n",
        "8\tBag (Bolsa)\n",
        "9\tAnkle boot (Bota alta)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg8LVOxCgOr2"
      },
      "source": [
        "Cada imagen corresponde a una etiqueta en particular, crearemos el arreglo de clases ya que éste no es proporcionado por el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rCaL2qTgX6r"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXiQXeRHgcda"
      },
      "source": [
        "Exploremos el Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNBOzHZrghVp",
        "outputId": "ff8aae05-6919-4224-ffb5-e85766946cdc"
      },
      "outputs": [],
      "source": [
        "print(train_images.shape)\n",
        "print(len(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR-P4vLbgmLX",
        "outputId": "41af70bd-9c2e-4c37-df5b-b18e1f91684d"
      },
      "outputs": [],
      "source": [
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3pJ6HaJgp9r",
        "outputId": "6d137b76-2211-4040-9ab6-61654a5bb2fd"
      },
      "outputs": [],
      "source": [
        "print(test_images.shape)\n",
        "print(len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSaac8V7guqr"
      },
      "source": [
        "## **Pre-procesamiento**\n",
        "\n",
        "Una vez que hemos cargado nuestro Dataset procederemos al siguiente paso: el pre-procesamiento o limpieza y estandarización de los datos. Como ya hemos mencionado antes, los colores siguen una escala de 0 a 255 por lo que típicamente cuando se trata de imágenes, usamos 255 para dividir cada valor y convertirlos a un valor entre 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DKbUQolrg9OL",
        "outputId": "bd7c4aaa-de62-4bc9-8da3-810def031072"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0], cmap=\"gray\")\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmUxXgSQhpAM"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXM4K9zdh3lM"
      },
      "source": [
        "Vamos a verificar que el conjunto de datos se encuentre en el formato adecuado desplegando las primeras 10 imágenes del *training set* y desplegaremos el nombre de cada clase debajo de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ahe0QC8Fmd8",
        "outputId": "37347889-4a2e-4e8f-b11f-fc793346ea38"
      },
      "outputs": [],
      "source": [
        "print(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "jfnx0FZviRXn",
        "outputId": "33b99da9-8513-4ce5-d542-f52b98fd60c1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-MRNJWajihm"
      },
      "source": [
        "## **Construir el modelo**\n",
        "\n",
        "Construir la red neuronal implica configurar las capas del modelo y posteriormente compilar el modelo.\n",
        "\n",
        "### Configurando las capas\n",
        "\n",
        "Los bloques de construcción básicos de una red neuronal son sus capas o *layers*.  La mayoría de las tareas del aprendizaje profundo (Deep learning) consiste en unir capas sencillas. La gran mayoría de los tipos de capas disponibles en la blibioteca Keras de Tensorflow tienen parámetros que se ajustarán (serán aprendidos) durante el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbn2Ge9OkTj6"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPKmiDBgkdf9"
      },
      "source": [
        "La primera capa de esta red, `tf.keras.layers.Flatten`, transforma el formato de las imágenes de un arreglo bi-dimensional (de 28 por 28 pixeles) a un arreglo uni dimensional (de 28x28 pixeles = 784 pixeles). Una capa *Flatten* no tiene parámetros que aprender, simplemente nos sirve para reformatear el conjunto de datos.\n",
        "\n",
        "Después de que los pixeles estan \"aplanados\", la secuencia consiste de dos capas `tf.keras.layers.Dense`. Estas están densamente conectadas, o completamente conectadas. La primera capa *Dense* tiene 128 nodos (o neuronas). La segunda (y última) capa es una capa de 10 nodos *softmax* que devuelve un arreglo de 10 probabilidades que suman a 1. Cada nodo contiene una calificacion que indica la probabilidad que la actual imagen pertenece a una de las 10 clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxDxBVJAlHsW"
      },
      "source": [
        "## **Compilando el modelo**\n",
        "\n",
        "Antes de que el modelo esté listo para entrenar, se necesitan algunas configuraciones más. Éstas son agregadas durante el paso de compilación del modelo:\n",
        "\n",
        "1.   *Loss function* (función de pérdida) —Esto mide que tan exacto es el modelo durante el entrenamiento. Quiere minimizar esta funcion para dirigir el modelo en la direccion adecuada.\n",
        "2.   *Optimizer* (optimizador) — Esto es como el modelo se actualiza basado en el conjunto de datos que ve y la función de pérdida.\n",
        "3.   *Metrics* (métricas) — Se usan para monitorear los pasos de entrenamiento y de pruebas. El siguiente ejemplo usa accuracy (exactitud), la fracción de la imágenes que son correctamente clasificadas.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yza0nLEol6Up"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxKkSTriC0wn"
      },
      "source": [
        "Mostramos un resumen del modelo creado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YClhvTQHCiZD",
        "outputId": "146ccf4d-e2f3-44ca-962b-28837784d65b"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI4ra_1Ol9Bw"
      },
      "source": [
        "## Entrenar el modelo\n",
        "\n",
        "Entrenar el modelo de red neuronal requiere de los siguientes pasos:\n",
        "\n",
        "1. Entregue los datos de entrenamiento al modelo. En este ejemplo, el conjunto de datos de entrenamiento está en los arreglos *train_images* y *train_labels*.\n",
        "2. el modelo aprende a asociar imágenes y etiquetas.\n",
        "3. Usted le pide al modelo que haga predicciones sobre un conjunto de datos que se encuentran en el ejemplo, incluido en el arreglo *test_images*. Verifique que las predicciones sean iguales a las etiquetas de el arreglo *test_labels*.\n",
        "\n",
        "Para comenzar a entrenar, llame el metodo `model.fit`, es llamado así por que fit (ajusta) el modelo al conjunto de datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqmSHDcJmhmF",
        "outputId": "2b47b401-bcba-4086-9262-c687dda3059f"
      },
      "outputs": [],
      "source": [
        "epocas = 10\n",
        "model.fit(train_images, train_labels, epochs=epocas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBZhTdQ1mt_d"
      },
      "source": [
        "A medida que el modelo entrena, la pérdida y la exactitud son desplegadas. Este modelo alcanza una exactitud cercana a  0.90 (o 90%) sobre el conjunto de datos de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR55c0ygnuob"
      },
      "source": [
        "## Evaluando la exactitud\n",
        "\n",
        "A continuación comparamos el rendimiento del modelo sobre el conjunto de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrmxHS_Bn5kn",
        "outputId": "ceef1f40-c8d8-42b3-cd8a-7ab830c8e1f9"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nPrueba de Exactitud (Test accuracy):', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR9cGFPBob2o"
      },
      "source": [
        "Como podemos ver la exactitud sobre el conjunto de datos de prueba es un poco menor que la exactitud sobre el conjunto de entrenamiento. Esta diferencia entre el entrenamiento (training) y el test se debe al overfitting (sobre ajuste). Sobre ajuste sucede cuando un modelo de aprendizaje máquina (ML) tiene un rendimiento menor sobre un conjunto de datos nuevo, que nunca antes ha visto comparado con el de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPWqfBjaozM4"
      },
      "source": [
        "## **Haciendo predicciones**\n",
        "\n",
        "Habiendo entrenado el modelo, podemos usarlo para hacer predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M2A8ZBNoxU0"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx0IJGPlpB5G"
      },
      "source": [
        "Con la línea de código anterior, hemos predecido la etiqueta de cada una de las imágenes del conjunto de prueba. Revisemos las predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cChtWD1BpOtC",
        "outputId": "0e0c5a29-a4d9-481b-a792-4df0b0380448"
      },
      "outputs": [],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDONNrGppUvw"
      },
      "source": [
        "Cada predicción es un arreglo de 10 números. Estos representan el nivel de \"confianza\" del modelo sobre las imágenes de cada uno de los 10 artículos de moda/ropa. Ustedes pueden revisar cual tiene el nivel más alto de confianza:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY24PsBCpg4g",
        "outputId": "49a51498-c277-4b47-aac4-b61c2a9aa61d"
      },
      "outputs": [],
      "source": [
        "np.argmax(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmpgfZJplRy"
      },
      "source": [
        "Entonces, el modelo tiene mayor confianza que esta imagen es un bota de tobillo \"ankle boot\" o class_names[9]. Examinando las etiquetas de test o de pruebas muestra que esta clasificación es correcta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAEMCF1rpuiK",
        "outputId": "c78301de-6047-46d6-f9b2-349a4a482af4"
      },
      "outputs": [],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkYL4Fmpy9a"
      },
      "source": [
        "Graficaremos el vector de predicciones para entender mejor lo anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQScikl_pydT"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIet5DtCqG-l"
      },
      "source": [
        "Revisemos la imagen [0] y la [12], sus predicciones y el arreglo de predicciones. Las etiquetas de predicción correctas están en azul y las incorrectas están en rojo. El número entrega el porcentaje (sobre 100) para la etiqueta predecida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TX4Sg31Vp_QY",
        "outputId": "fcc2cbc5-e145-4322-a20e-6db1423a3a78"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "d6ZxmZM9q8mp",
        "outputId": "bc7baef4-0a40-4618-8195-ceca47b73fd8"
      },
      "outputs": [],
      "source": [
        "i = 5\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzpiPa3MrEgg"
      },
      "source": [
        "Ahora se mostrarán varias imágenes con su predicciones. Nótese que el modelo puede arrojar una predicción incorrecta aún cuando tenga mucha certeza sobre su predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "7K-5KGmCrecS",
        "outputId": "bdbdef25-e841-436b-f912-06e2f83bad10"
      },
      "outputs": [],
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Muestra las x primeras imágenes, sus etiquetas predecidas y los valores reales.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "# Las predicciones correctas están en azul y las incorrectas en rojo.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sof9T-gzsIoy"
      },
      "source": [
        "Finalmente, usaremos el modelo entrenado para hacer una predicción sobre una única imagen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxth6yWQsPzA",
        "outputId": "b96490e3-38fb-4be3-c4ec-0cd2ed535552"
      },
      "outputs": [],
      "source": [
        "# Grab an image from the test dataset.\n",
        "# Tomamos una imagen del dataset de pruebas.\n",
        "img = test_images[1]\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "NcI0bl-Rt4vb",
        "outputId": "f20c05e5-4059-46fd-c155-c7f95a687768"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.imshow(img)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "168pgfZgsW0-"
      },
      "source": [
        "Los modelos de tf.keras son optimizados sobre batch o bloques, o colecciones de ejemplos por vez. De acuerdo a esto, aunque se use una única imagen hay agregarla a una lista:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCgbXD_PsWVe",
        "outputId": "b9037809-04ca-4810-e17c-f6e6312f6b9c"
      },
      "outputs": [],
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "# Agregamos la imagen a un lote donde es el único miembro\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wQ3gok5shLv"
      },
      "source": [
        "Hagamos la predicción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GKj16EYsjPz",
        "outputId": "17ae9d51-8cef-4927-dd4a-5ff151403639"
      },
      "outputs": [],
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EIGk2Tlrsmse",
        "outputId": "64adaab8-0ba8-4964-949f-a70e44f7d6f9"
      },
      "outputs": [],
      "source": [
        "plot_value_array(1, predictions_single[0], test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtKntn8wssgV"
      },
      "source": [
        "*model.predict* retorna una lista de listas para cada imagen dentro del batch o bloque de datos. Tomemos la predicción para nuestra única imagen dentro del batch o bloque:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX_AmFSss0H-",
        "outputId": "7104c557-e45b-4557-9b72-1fdb053cac78"
      },
      "outputs": [],
      "source": [
        "np.argmax(predictions_single[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNmxCFMXs4a9"
      },
      "source": [
        "El modelo predice una etiqueta de 2, que corresponde a la clase ubicada en esa posición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_0qLNdzs_3z",
        "outputId": "8d14c832-975d-4f50-c569-b150ef0ae972"
      },
      "outputs": [],
      "source": [
        "print(class_names[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is48--YVwyBU"
      },
      "source": [
        "## **Cierre**\n",
        "Hemos llegado al final de la práctica, utilizamos el dataset de [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) que contiene más de 70,000 imágenes en 10 categorías o clases. Las imágenes están en una resolución de 28x28 y muestran artículos de ropa.\n",
        "\n",
        "<img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\" style=\"width:650px;height:400px;\">\n",
        "\n",
        "Figura 1. Ejemplos de Fashion-MNIST (por Zalando, MIT License).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkkSh_thwvmo"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ketIjKUGtQbm"
      },
      "source": [
        "Respetando los derechos de autor, incluyo la declaración de Copyright ya que este ejemplo está basado en la documentación de TensorFlow disponible en: https://www.tensorflow.org/tutorials/keras/classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_t8NYLEtXPu"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
